{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39b4a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "import string\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "from PyPDF2 import PdfFileReader\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78a105c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "\n",
    "# Find words in a string from a list of words\n",
    "def words_in_string(word_list, a_string):\n",
    "    \n",
    "    set_matching_words = set(word_list).intersection(a_string.split())\n",
    "    \n",
    "    list_matching_words = list(set_matching_words)\n",
    "        \n",
    "    return list_matching_words\n",
    "\n",
    "# Replace items in a list based on values in a dictionary\n",
    "def replace(my_list, my_dict):\n",
    "    \n",
    "    new_list = [item if item not in my_dict else my_dict[item] for item in my_list]\n",
    "    \n",
    "    return new_list\n",
    "\n",
    "# Generate list of strings generated from combination of all possible permutations of substrings from two lists\n",
    "def permutations(list1, list2, separator = ''):\n",
    "    \n",
    "    permutations = list(itertools.product(list1, list2))\n",
    "    \n",
    "    permutations = [permutations[i][0] + separator + permutations[i][1] for i in range(0, len(permutations))]\n",
    "    \n",
    "    return permutations\n",
    "\n",
    "# Extracting relevant strings\n",
    "def relevant_strings_from_pdf(text_from_pdf):\n",
    "\n",
    "    # Find strings containg specific sequence\n",
    "    relevant_strings_from_pdf = re.findall(\"\\n[ \\w,.*'\\-();0-9]+\", text_from_pdf)\n",
    "\n",
    "    # Generate strings used to seperate words by first letter\n",
    "    alphabet_uppercase = list(string.ascii_uppercase)\n",
    "    alphabet_lowercase = list(string.ascii_lowercase)\n",
    "    alphabet_rows = []\n",
    "\n",
    "    for upper, lower in zip(alphabet_uppercase, alphabet_lowercase):\n",
    "\n",
    "        row_to_remove = \"\\n\" + upper + lower\n",
    "\n",
    "        alphabet_rows.append(row_to_remove)\n",
    "\n",
    "    # Remove rows with strings used to seperate words by first letter\n",
    "    relevant_strings_from_pdf = list(set(relevant_strings_from_pdf).difference(alphabet_rows))\n",
    "\n",
    "    # Remove rows that are used to seperate pages\n",
    "    relevant_strings_from_pdf = [row for row in relevant_strings_from_pdf if '\\n Page ' not in row]\n",
    "\n",
    "    # Remove rows with a blank space\n",
    "    relevant_strings_from_pdf = [row for row in relevant_strings_from_pdf if row != '\\n ']\n",
    "    \n",
    "    # Remove trailling letters of strings if they exist\n",
    "    for index, relevant_string in enumerate(relevant_strings_from_pdf):\n",
    "        \n",
    "        if relevant_string[-1].isalpha() == True:\n",
    "            \n",
    "            relevant_strings_from_pdf[index] = re.sub('[a-zA-Z]+$', '', relevant_string)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            relevant_strings_from_pdf[index] = relevant_string\n",
    "\n",
    "    return relevant_strings_from_pdf\n",
    "\n",
    "# Flatten a list\n",
    "def flatten_list(list_of_lists):\n",
    "    \n",
    "    return list(itertools.chain(*list_of_lists))\n",
    "\n",
    "# Due to an error in the pdf, a specific replacement with respect to the rank frequency column is required\n",
    "def make_specific_replacement_due_to_error_in_pdf(dataframe):\n",
    "    \n",
    "    # List of numbers from 1 to 5000\n",
    "    first_5000_numbers = list(range(1, 5000))\n",
    "\n",
    "    # List of numbers we have in our dataframe\n",
    "    numbers_present = list(dataframe['Rank Frequency'])\n",
    "\n",
    "    # Check to see if we have all 5000 words in dataframe\n",
    "    check = list(set(first_5000_numbers).difference(numbers_present)) \n",
    "\n",
    "    # 'check' returns [4149], we are missing this number only\n",
    "\n",
    "    # From looking at the pdf, turns out there are two words paired with 4436 (vingt-cinq and vingt-quatre)\n",
    "    view_error = dataframe[dataframe['Rank Frequency'] == 4436]\n",
    "\n",
    "    # vingt-quatre should paired with 4149\n",
    "    \n",
    "    # find index of vingt-quatre\n",
    "    index_of_error = df.loc[df['French Word'] == 'vingt-quatre'].index[0]\n",
    "    \n",
    "    # Make the replacement\n",
    "    dataframe.at[index_of_error,'Rank Frequency'] = 4149\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "# Due to errors in the pdf (noticed due to mismatches between different sections within the pdf) \n",
    "# specific replacement with respect to typos are required\n",
    "def make_specific_replacement_due_to_error_in_pdf_2(text_from_pdf):\n",
    "    \n",
    "    text_from_pdf = text_from_pdf.replace('2010 bien? adv well', '2010 ben adv well')\n",
    "    \n",
    "    text_from_pdf = text_from_pdf.replace('2084 résiderv to reside', '2084 résider v to reside')\n",
    "    \n",
    "    text_from_pdf = text_from_pdf.replace('3313 assdassinat nm murder, assassination', '3313 assassinat nm murder, assassination')\n",
    "\n",
    "    return text_from_pdf\n",
    "\n",
    "# Find all index positions of item in a list\n",
    "def get_index_positions(list_of_elems, element):\n",
    "    \n",
    "    index_pos_list = []\n",
    "    \n",
    "    index_pos = 0\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # Search for item in list from indexPos to the end of list\n",
    "            index_pos = list_of_elems.index(element, index_pos)\n",
    "            \n",
    "            # Add the index position in list\n",
    "            index_pos_list.append(index_pos)\n",
    "            \n",
    "            index_pos += 1\n",
    "            \n",
    "        except ValueError as e:\n",
    "            \n",
    "            break\n",
    "            \n",
    "    return index_pos_list\n",
    "\n",
    "# Generating more permutations for the parts of speech formatting: e.g. [POS A], [POS B] or [POS A],[POS B]\n",
    "def add_parts_of_speech_formating_premutation(string):\n",
    "    \n",
    "    formatting_permutation = string.replace(', ', ',')\n",
    "    \n",
    "    formatting_permutations = [string, formatting_permutation]\n",
    "    \n",
    "    return formatting_permutations\n",
    "\n",
    "# Sort list by another list\n",
    "def sort_list_by_another_list(list_to_sort_by, list_to_sort):\n",
    "    \n",
    "    sorted_list = [x for _, x in sorted(zip(list_to_sort_by, list_to_sort))]\n",
    "    \n",
    "    return sorted_list\n",
    "\n",
    "# Find matching items between two lists and maintain order of these items ('set()' may change the original order)\n",
    "def find_matching_items_between_two_lists_and_maintain_order(list_to_maintain_order_of, list_to_check_for_matching_items):\n",
    "    \n",
    "    items_and_index = [(item, index) for index, item in enumerate(list_to_maintain_order_of)]\n",
    "    \n",
    "    list_matching_items = list(set(list_to_maintain_order_of) & set(list_to_check_for_matching_items))\n",
    "    \n",
    "    prior_index_of_items_in_list_to_maintain_order_of = [tup[1] for item in list_matching_items for tup in items_and_index if tup[0] == item]\n",
    "    \n",
    "    list_matching_items_order_maintained = sort_list_by_another_list(prior_index_of_items_in_list_to_maintain_order_of, list_matching_items)\n",
    "    \n",
    "    return list_matching_items_order_maintained\n",
    "\n",
    "# Find text starting with a specified string and ending with a specified string\n",
    "def find_text_starting_with_x_and_ending_with_y(full_text, starting_with, ending_with='|'):\n",
    "        \n",
    "    full_text_reduced = full_text[full_text.find(starting_with):]\n",
    "        \n",
    "    final_text = full_text_reduced[:full_text_reduced.find(ending_with)]\n",
    "    \n",
    "    return final_text\n",
    "\n",
    "# Find strings without a specific item (e.g. asterisk, double dash etc.) as these normally signify where the sentences begin and end\n",
    "def find_strings_without_a_specific_item(string, item):\n",
    "        \n",
    "    if item in string:\n",
    "        \n",
    "        output = 'Yes'\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        output = 'No'\n",
    "        \n",
    "    return output\n",
    "\n",
    "# Add missing items to strings (e.g. if string does not contain an asterisk, add it at the appropriate place)\n",
    "def add_missing_items_to_strings(dataframe, column_with_strings, item, string_to_replace, string_to_replace_with):\n",
    "    \n",
    "    df_temp = pd.DataFrame()\n",
    "    \n",
    "    df_temp[column_with_strings] = dataframe[column_with_strings]\n",
    "\n",
    "    df_temp['Check Item Missing'] = df_temp[column_with_strings].apply(lambda x: find_strings_without_a_specific_item(x, item))\n",
    "    \n",
    "    list_strings_original = list(df_temp[df_temp['Check Item Missing'] == 'No'][column_with_strings])\n",
    "    \n",
    "    list_strings_replace = [string.replace(string_to_replace, string_to_replace_with, 1) for string in list_strings_original]\n",
    "    \n",
    "    for original, replace in zip(list_strings_original, list_strings_replace):\n",
    "    \n",
    "        dataframe = dataframe.replace(to_replace = original, value = replace)\n",
    "        \n",
    "    return dataframe\n",
    "\n",
    "# Remove new lines from a string\n",
    "def remove_new_lines(string):\n",
    "    \n",
    "    string = string.replace('\\n', '   ')\n",
    "    \n",
    "    string = re.sub(' +', ' ', string)\n",
    "    \n",
    "    return string\n",
    "\n",
    "# Count number of substring in a string\n",
    "def count_substring_in_string(main_string, sub_string):\n",
    "    \n",
    "    count = main_string.count(sub_string)\n",
    "    \n",
    "    return count\n",
    "\n",
    "# Remove additional occurances of item in a string (e.g. more than one double dash)\n",
    "def remove_additional_occurances_of_item_in_string(dataframe, column_with_strings, item, replace_with):\n",
    "    \n",
    "    df_temp = pd.DataFrame()\n",
    "    \n",
    "    df_temp[column_with_strings] = dataframe[column_with_strings]\n",
    "\n",
    "    df_temp['Count'] = df_temp['String with Sentences'].apply(lambda x: count_substring_in_string(x, item))\n",
    "\n",
    "    list_strings_original = df_temp[df_temp['Count'] > 1]['String with Sentences'].to_list()\n",
    "    \n",
    "    list_strings_replace = [item.replace('---', '--') for item in list_strings_original]\n",
    "    \n",
    "    for index, item in enumerate(list_strings_replace):\n",
    "        \n",
    "        parts = item.partition(\"--\")\n",
    "        \n",
    "        list_strings_replace[index] = parts[0] + parts[1] + parts[2].replace(\"--\", replace_with)\n",
    "        \n",
    "    for original, replace in zip(list_strings_original, list_strings_replace):\n",
    "    \n",
    "        dataframe = dataframe.replace(to_replace = original, value = replace)\n",
    "        \n",
    "    return dataframe\n",
    "\n",
    "# Extract french and english sentences from string\n",
    "def extract_sentences(string):\n",
    "    \n",
    "    string_clean = string.strip()\n",
    "\n",
    "    sentence_french = re.search('\\*(.*)\\--', string_clean).group(1)\n",
    "    sentence_french = sentence_french.replace('*', '')\n",
    "    sentence_french = sentence_french.strip()\n",
    "\n",
    "    start_of_english_sentence = '--' \n",
    "    sentence_english = string_clean[string_clean.find(start_of_english_sentence):]\n",
    "    sentence_english = sentence_english.replace('--', '') \n",
    "    sentence_english = re.sub('[0-9]+$', '', sentence_english)\n",
    "    sentence_english = sentence_english.strip()\n",
    "        \n",
    "    return sentence_french, sentence_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e927637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pdf file reader object\n",
    "pdf = PdfFileReader('French Words Book.pdf')\n",
    "\n",
    "# Define pages to extract text from\n",
    "page_range = range(475, 575)\n",
    "\n",
    "relevant_strings = []\n",
    "\n",
    "# For each page, do the following:\n",
    "for page_number in page_range:\n",
    "    \n",
    "    # Find the page \n",
    "    page_object = pdf.getPage(page_number)\n",
    "    \n",
    "    # Extract text from the page\n",
    "    text_from_pdf = page_object.extractText()\n",
    "        \n",
    "    # Modify start of text as required\n",
    "    if page_range.index(page_number) == 0:\n",
    "        \n",
    "        find_text = \"\\nAa\"\n",
    "        \n",
    "        text_from_pdf = text_from_pdf[text_from_pdf.find(find_text):]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        text_from_pdf = \"\\n\" + text_from_pdf\n",
    "\n",
    "    # Extract relevant strings from the text\n",
    "    relevant_strings_from_page = relevant_strings_from_pdf(text_from_pdf)\n",
    "            \n",
    "    # Save relevent strings from page to list\n",
    "    relevant_strings.append(relevant_strings_from_page)\n",
    "\n",
    "relevant_strings = flatten_list(relevant_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ed376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of different parts of speech and their abbreviations\n",
    "dict_parts_of_speech = {'adj':'adjective', 'adv':'adverb', 'conj':'conjunction', 'det':'determiner',\n",
    "                  'intj':'interjection', 'n':'noun', 'nadj':'noun/adjective', 'prep':'preposition',\n",
    "                  'pro':'pronoun', 'v':'verb'}\n",
    "\n",
    "# List of the different parts of speech \n",
    "parts_of_speech_short = list(dict_parts_of_speech.keys())\n",
    "parts_of_speech_long = list(dict_parts_of_speech.values())\n",
    "\n",
    "# Dictionary of different features and their abbreviations\n",
    "dict_features = {'f':'(feminine)', 'i':'(invariable)', 'm':'(masculine)', 'pl':'(plural)',\n",
    "                '(' + 'f' + ')':'(no distinct feminine)', '(' + 'pl' + ')':'(no distinct plural)'}\n",
    "\n",
    "# List of the different features\n",
    "features_short = list(dict_features.keys())\n",
    "features_long = list(dict_features.values())\n",
    "\n",
    "# Generate all possible permutations of parts of speech + features (x2)\n",
    "feature_permutations_short = features_short + permutations(features_short, features_short)\n",
    "feature_permutations_short = [item.replace(\")(\", \"\") for item in feature_permutations_short]\n",
    "\n",
    "feature_permutations_long = features_long + permutations(features_long, features_long, '')\n",
    "feature_permutations_long = [item.replace(\")(\", \" \") for item in feature_permutations_long]\n",
    "\n",
    "permutations_short = permutations(parts_of_speech_short, feature_permutations_short)\n",
    "permutations_long = permutations(parts_of_speech_long, feature_permutations_long, ' ')\n",
    "\n",
    "# Append original parts of speech list to permutations list\n",
    "parts_of_speech_and_features_short = parts_of_speech_short + permutations_short\n",
    "parts_of_speech_and_features_long = parts_of_speech_long + permutations_long\n",
    "\n",
    "# Creating new dictionary with original parts of speech and all permutations\n",
    "dict_parts_of_speech_and_features = {parts_of_speech_and_features_short[i]:parts_of_speech_and_features_long[i] \n",
    "                                     for i in range(len(parts_of_speech_and_features_short))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f13f4c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalising dataframe\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b6f17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalising lists for different \n",
    "numbers = []\n",
    "words_french = []\n",
    "words_english = []\n",
    "parts_of_speech_short = []\n",
    "parts_of_speech_long = []\n",
    "sentences_french = []\n",
    "sentences_english = []\n",
    "\n",
    "\n",
    "# Iterating across all string\n",
    "for row in relevant_strings:\n",
    "        \n",
    "    # Extract number\n",
    "    number = re.search(\"[0-9]+\", row).group(0)\n",
    "    numbers.append(int(number))\n",
    "        \n",
    "    # Extract French word\n",
    "    row = row.replace(number, \"\")\n",
    "        \n",
    "    substrings = row.split()\n",
    "    \n",
    "    word_french = substrings[0]\n",
    "    words_french.append(word_french)\n",
    "            \n",
    "    # Extract part of speech\n",
    "    substrings = substrings[1:]\n",
    "    \n",
    "    substrings = [substring.split(',') for substring in substrings]\n",
    "    substrings = flatten_list(substrings)\n",
    "\n",
    "    list_poc_short = find_matching_items_between_two_lists_and_maintain_order(substrings, parts_of_speech_and_features_short)\n",
    "    list_poc_long = replace(list_poc_short, dict_parts_of_speech_and_features)\n",
    "       \n",
    "    string_poc_short = ', '.join(list_poc_short)\n",
    "    string_poc_long = ', '.join(list_poc_long)\n",
    "    \n",
    "    parts_of_speech_short.append(string_poc_short)\n",
    "    parts_of_speech_long.append(string_poc_long)\n",
    "    \n",
    "    # Extract English word\n",
    "    substrings = [item for item in substrings if item not in list_poc_short]\n",
    "    substrings = [',' if item == \"\" else item for item in substrings]\n",
    "    \n",
    "    word_english = ' '.join(substrings)\n",
    "    word_english = word_english.replace(\" ,\", \",\")\n",
    "    words_english.append(word_english)\n",
    "\n",
    "# Adding list to dataframe\n",
    "df['Rank Frequency'] = numbers\n",
    "df['French Word'] = words_french\n",
    "df['Meaning'] = words_english\n",
    "df['Parts of Speech (Abbreviated)'] = parts_of_speech_short\n",
    "df['Parts of Speech'] = parts_of_speech_long\n",
    "\n",
    "# Due to an error in the pdf, a specific replacement with respect to the rank frequency column is required\n",
    "df = make_specific_replacement_due_to_error_in_pdf(df)\n",
    "\n",
    "# Sort values by rank frequency column\n",
    "df = df.sort_values('Rank Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "800e19ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pages to extract text from\n",
    "page_range = range(17, 476)\n",
    "\n",
    "# Initiate string to add text too\n",
    "text_from_pdf = ''\n",
    "\n",
    "# For each page, do the following:\n",
    "for page_number in page_range:\n",
    "    \n",
    "    # Find the page \n",
    "    page_object = pdf.getPage(page_number)\n",
    "    \n",
    "    # Extract text from the page\n",
    "    text_from_pdf += page_object.extractText()\n",
    "    \n",
    "text_from_pdf = make_specific_replacement_due_to_error_in_pdf_2(text_from_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd700df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to find sentences\n",
    "df_find_sentences = pd.DataFrame()\n",
    "\n",
    "# Copy over the Rank Frequency column from original dataframe\n",
    "df_find_sentences['Rank Frequency'] = df['Rank Frequency']\n",
    "\n",
    "# Generate strings to search for in text \n",
    "df_find_sentences['Number and Word'] = df.apply(lambda x: f\"{x['Rank Frequency']} {x['French Word']} \", axis = 1)\n",
    "\n",
    "# Find strings with sentences\n",
    "df_find_sentences['String with Sentences'] = df_find_sentences['Number and Word'].apply(lambda x: find_text_starting_with_x_and_ending_with_y(text_from_pdf, x))\n",
    "\n",
    "# Add asterisks at the appropriate place to strings without asterisks\n",
    "df_find_sentences = add_missing_items_to_strings(df_find_sentences, 'String with Sentences', '*', '\\n', '\\n*')\n",
    "\n",
    "# Remove new lines from a string\n",
    "df_find_sentences['String with Sentences'] = df_find_sentences['String with Sentences'].apply(lambda x: remove_new_lines(x))\n",
    "\n",
    "# Add double dashes at the appropriate place to strings without double dashes\n",
    "df_find_sentences = add_missing_items_to_strings(df_find_sentences, 'String with Sentences', ' --', ' - ', ' -- ')\n",
    "\n",
    "# Remove additional occurances of double dashes after the first occurance (and replace them with commas)\n",
    "df_find_sentences = remove_additional_occurances_of_item_in_string(df_find_sentences, 'String with Sentences', '--', ', ')\n",
    "\n",
    "# Extract French sentences\n",
    "df_find_sentences['French Sentence'] = df_find_sentences['String with Sentences'].apply(lambda x: extract_sentences(x)[0])\n",
    "\n",
    "# Extract English sentences\n",
    "df_find_sentences['English Sentence'] = df_find_sentences['String with Sentences'].apply(lambda x: extract_sentences(x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baf6ccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_find_sentences = remove_additional_occurances_of_item_in_string(df_find_sentences, 'String with Sentences', '--', ', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fdb7d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank Frequency</th>\n",
       "      <th>French Word</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>Parts of Speech (Abbreviated)</th>\n",
       "      <th>Parts of Speech</th>\n",
       "      <th>French Sentence</th>\n",
       "      <th>English Sentence</th>\n",
       "      <th>Already Seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>le</td>\n",
       "      <td>the; him, her, it, them</td>\n",
       "      <td>det, pro</td>\n",
       "      <td>determiner, pronoun</td>\n",
       "      <td>vive la politique, vive l'amour</td>\n",
       "      <td>long live politics, long live love</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>de</td>\n",
       "      <td>of, from, some, any</td>\n",
       "      <td>det, prep</td>\n",
       "      <td>determiner, preposition</td>\n",
       "      <td>il ne rêve que d'argent et de plaisirs</td>\n",
       "      <td>he only dreams of money and pleasure</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>un</td>\n",
       "      <td>a, an, one</td>\n",
       "      <td>adj, det, nm, pro</td>\n",
       "      <td>adjective, determiner, noun (masculine), pronoun</td>\n",
       "      <td>je me suis cassé un ongle</td>\n",
       "      <td>I broke one of my fingernails</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>à</td>\n",
       "      <td>to, at, in</td>\n",
       "      <td>prep</td>\n",
       "      <td>preposition</td>\n",
       "      <td>ils restent à l'école le plus longtemps possible</td>\n",
       "      <td>they remain at school as long as possible</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>être</td>\n",
       "      <td>to be; being</td>\n",
       "      <td>nm, v</td>\n",
       "      <td>noun (masculine), verb</td>\n",
       "      <td>tout le monde veut être beau</td>\n",
       "      <td>everybody wants to be beautiful</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4996</td>\n",
       "      <td>réfléchi</td>\n",
       "      <td>thoughtful, well thought-out</td>\n",
       "      <td>adj</td>\n",
       "      <td>adjective</td>\n",
       "      <td>nous devrions agir de façon réfléchie et respo...</td>\n",
       "      <td>we should act in a thoughtful and responsible ...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4997</td>\n",
       "      <td>expérimenter</td>\n",
       "      <td>to experiment</td>\n",
       "      <td>v</td>\n",
       "      <td>verb</td>\n",
       "      <td>les skieurs peu expérimentés devraient renonce...</td>\n",
       "      <td>inexperienced skiers should forego racing</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4998</td>\n",
       "      <td>détériorer</td>\n",
       "      <td>to deteriorate</td>\n",
       "      <td>v</td>\n",
       "      <td>verb</td>\n",
       "      <td>il a laissé nos routes se détériorer et se dés...</td>\n",
       "      <td>he has let our roads deteriorate and disintegrate</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4999</td>\n",
       "      <td>exprès</td>\n",
       "      <td>deliberately, on purpose, intentionally</td>\n",
       "      <td>adj(pl), adv</td>\n",
       "      <td>adjective (no distinct plural), adverb</td>\n",
       "      <td>je ne le fais pas exprès ou plutôt ce n'est pa...</td>\n",
       "      <td>I don't do it on purpose, or rather it's not c...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>5000</td>\n",
       "      <td>écrouler</td>\n",
       "      <td>to collapse, tumble</td>\n",
       "      <td>v</td>\n",
       "      <td>verb</td>\n",
       "      <td>on le trouva mort, écroulé dans les W.C.</td>\n",
       "      <td>they found him dead, collapsed in the restroom</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rank Frequency   French Word                                  Meaning  \\\n",
       "0                  1            le                  the; him, her, it, them   \n",
       "1                  2            de                      of, from, some, any   \n",
       "2                  3            un                               a, an, one   \n",
       "3                  4             à                               to, at, in   \n",
       "4                  5          être                             to be; being   \n",
       "...              ...           ...                                      ...   \n",
       "4995            4996      réfléchi             thoughtful, well thought-out   \n",
       "4996            4997  expérimenter                            to experiment   \n",
       "4997            4998    détériorer                           to deteriorate   \n",
       "4998            4999        exprès  deliberately, on purpose, intentionally   \n",
       "4999            5000      écrouler                      to collapse, tumble   \n",
       "\n",
       "     Parts of Speech (Abbreviated)  \\\n",
       "0                         det, pro   \n",
       "1                        det, prep   \n",
       "2                adj, det, nm, pro   \n",
       "3                             prep   \n",
       "4                            nm, v   \n",
       "...                            ...   \n",
       "4995                           adj   \n",
       "4996                             v   \n",
       "4997                             v   \n",
       "4998                  adj(pl), adv   \n",
       "4999                             v   \n",
       "\n",
       "                                       Parts of Speech  \\\n",
       "0                                  determiner, pronoun   \n",
       "1                              determiner, preposition   \n",
       "2     adjective, determiner, noun (masculine), pronoun   \n",
       "3                                          preposition   \n",
       "4                               noun (masculine), verb   \n",
       "...                                                ...   \n",
       "4995                                         adjective   \n",
       "4996                                              verb   \n",
       "4997                                              verb   \n",
       "4998            adjective (no distinct plural), adverb   \n",
       "4999                                              verb   \n",
       "\n",
       "                                        French Sentence  \\\n",
       "0                       vive la politique, vive l'amour   \n",
       "1                il ne rêve que d'argent et de plaisirs   \n",
       "2                             je me suis cassé un ongle   \n",
       "3      ils restent à l'école le plus longtemps possible   \n",
       "4                          tout le monde veut être beau   \n",
       "...                                                 ...   \n",
       "4995  nous devrions agir de façon réfléchie et respo...   \n",
       "4996  les skieurs peu expérimentés devraient renonce...   \n",
       "4997  il a laissé nos routes se détériorer et se dés...   \n",
       "4998  je ne le fais pas exprès ou plutôt ce n'est pa...   \n",
       "4999           on le trouva mort, écroulé dans les W.C.   \n",
       "\n",
       "                                       English Sentence Already Seen  \n",
       "0                    long live politics, long live love           No  \n",
       "1                  he only dreams of money and pleasure           No  \n",
       "2                         I broke one of my fingernails           No  \n",
       "3             they remain at school as long as possible           No  \n",
       "4                       everybody wants to be beautiful           No  \n",
       "...                                                 ...          ...  \n",
       "4995  we should act in a thoughtful and responsible ...           No  \n",
       "4996          inexperienced skiers should forego racing           No  \n",
       "4997  he has let our roads deteriorate and disintegrate           No  \n",
       "4998  I don't do it on purpose, or rather it's not c...           No  \n",
       "4999     they found him dead, collapsed in the restroom           No  \n",
       "\n",
       "[5000 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe only for sentences\n",
    "df_sentences = df_find_sentences[['Rank Frequency', 'French Sentence', 'English Sentence']]\n",
    "\n",
    "# Merge sentences dataframe with original dataframe\n",
    "df = pd.merge(df, df_sentences, on='Rank Frequency')\n",
    "\n",
    "# Initialise a new column to record which rows have already been used by the application \n",
    "# (i.e. user has already recieved a message pertaining to that word)\n",
    "df['Already Seen'] = ['No'] * df.shape[0]\n",
    "\n",
    "# Show final dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d60f48ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save main dataframe to an excel file\n",
    "df.to_excel(\"Output\\French Words.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69777f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save find sentences dataframe to an excel file\n",
    "df_find_sentences.to_excel(\"Output\\Find Sentences.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
